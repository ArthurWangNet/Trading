{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this script\n",
    "This script is used for testing how to improve speed of updating files with multiprocess.\n",
    "The test shows great improvement\n",
    "And at last the results are identical between traditional for loop and multiprocess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import Paths\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data/Fundamental/Updates/2021-11-23',\n",
       " './Data/Fundamental/Updates/2021-11-25',\n",
       " './Data/Fundamental/Updates/2021-11-26']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all sub folders in the given folder\n",
    "def list_subfolders(folder):\n",
    "\treturn [f.path for f in os.scandir(folder) if f.is_dir()]\n",
    "\n",
    "update_folders = list_subfolders(Paths.Fundamental_Data_Update_Folder)\n",
    "update_folders.sort()\n",
    "update_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv(csv_file):\n",
    "\tif csv_file in production_csv_files:\n",
    "\t\t\t\t#print(csv_file + \" already in production folder, updating.\")\n",
    "\t\t\t# append the update csv file to the production csv file\n",
    "\t\t\tdf_update = pd.read_csv(os.path.join(folder, csv_file))\n",
    "\t\t\t# Add new column to the dataframe with value, this is the update date stamp\n",
    "\t\t\tdf_update['Update_Date'] =update_time_stamp \n",
    "\n",
    "\t\t\t#For the production files:\n",
    "\t\t\tdf_production = pd.read_csv(os.path.join(Paths.Fundamental_Data_Production_Folder, csv_file))\n",
    "\t\t\tdf_production = df_production.append(df_update)\n",
    "\t\t\tdf_production.to_csv(os.path.join(Paths.Fundamental_Data_Production_Folder, csv_file), index=False)\n",
    "\t\t\t#\tprint(csv_file + \" updated.\")\n",
    "\telse:\n",
    "\t\t# create new csv file in the production folder with the update date stamp\n",
    "\t\t\t#print(csv_file + \" not in production folder, creating new file.\")\n",
    "\t\tdf_update = pd.read_csv(os.path.join(folder, csv_file))\n",
    "\t\t# Add new column to the dataframe with value, this is the update date stamp\n",
    "\t\tdf_update['Update_Date'] =update_time_stamp\n",
    "\t\tdf_update.to_csv(os.path.join(Paths.Fundamental_Data_Production_Folder, csv_file), index=False)\n",
    "\t\t\t#print(csv_file + \" created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_update():\n",
    "\t#Using multiprocessing to speed up the process\n",
    "\tpool = Pool(os.cpu_count())\n",
    "\tpool.map(update_csv, update_csv_files)\n",
    "\tpool.close()\n",
    "\tpool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking update folder: 2021-11-23\n",
      "Start Multiprocessing for folder: 2021-11-23\n",
      "Finished Multiprocessing for folder: 2021-11-23\n",
      "Update folder moved to archive folder.\n",
      "Checking update folder: 2021-11-25\n",
      "Start Multiprocessing for folder: 2021-11-25\n",
      "Finished Multiprocessing for folder: 2021-11-25\n",
      "Update folder moved to archive folder.\n",
      "Checking update folder: 2021-11-26\n",
      "Start Multiprocessing for folder: 2021-11-26\n",
      "Finished Multiprocessing for folder: 2021-11-26\n",
      "Update folder moved to archive folder.\n",
      "--- 59.00800704956055 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for folder in update_folders:\n",
    "\t# Get update folder names from path, it will be a update date stamp.\n",
    "\tupdate_time_stamp= folder.split('/')[-1]\n",
    "\tprint(\"Checking update folder: \" + update_time_stamp)\n",
    "\t# Get files from folder which ends with csv and store them into a list\n",
    "\tupdate_csv_files = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\tproduction_csv_files = [f for f in os.listdir(Paths.Fundamental_Data_Production_Folder) if f.endswith('.csv')]\n",
    "\n",
    "\tprint(\"Start Multiprocessing for folder: \" + update_time_stamp)\n",
    "\n",
    "\tmulti_update()\n",
    "\t\n",
    "\tprint(\"Finished Multiprocessing for folder: \" + update_time_stamp)\n",
    "\t#Move the update folder and all its files to the archive folder\n",
    "\tos.rename(folder, os.path.join(Paths.Fundamental_Data_Archived_Folder, update_time_stamp))\n",
    "\tprint(\"Update folder moved to archive folder.\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare if two directories contians the same files\n",
    "def compare_dir(dir1, dir2):\n",
    "\tdir1_files = [f for f in os.listdir(dir1) if f.endswith('.csv')]\n",
    "\tdir2_files = [f for f in os.listdir(dir2) if f.endswith('.csv')]\n",
    "\treturn set(dir1_files) == set(dir2_files)\n",
    "\n",
    "dir2 = Paths.Fundamental_Data_Production_Folder + \"-For-Loop\"\n",
    "difference = compare_dir(Paths.Fundamental_Data_Production_Folder, dir2)\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if two csv files are identical\n",
    "def compare_csv(file1, file2):\n",
    "\tdf1 = pd.read_csv(os.path.join(Paths.Fundamental_Data_Production_Folder, file1))\n",
    "\tdf2 = pd.read_csv(os.path.join(Paths.Fundamental_Data_Production_Folder, file2))\n",
    "\treturn df1.equals(df2)\n",
    "\n",
    "loop_files = [f for f in os.listdir(dir2) if f.endswith('.csv')]\n",
    "mp_files = [f for f in os.listdir(Paths.Fundamental_Data_Production_Folder) if f.endswith('.csv')]\n",
    "\n",
    "diff_list = []\n",
    "for lp_file in loop_files:\n",
    "\tif lp_file in mp_files:\n",
    "\t\tlp_df = pd.read_csv(os.path.join(dir2, lp_file))\n",
    "\t\tmp_df = pd.read_csv(os.path.join(Paths.Fundamental_Data_Production_Folder, lp_file))\n",
    "\t\tif lp_df.equals(mp_df):\n",
    "\t\t\t# Do nothing\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\tprint(lp_file + \" is not in the multiprocessing folder.\")\n",
    "\t\t\tdiff_list.append(lp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72c29718af5f6d5698aef5128c7a322e07cf1de69fcce3aed1d5f85ab10241e8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
